{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlcivarJoffre-A6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMkOr03sOz3F"
      },
      "source": [
        "PolitiFact.com publishes fact-checks on politician's statements.  I collected a dataset of Donald Trump's quotes for this assignment.\n",
        "\n",
        "1. Import and pre-process the dataset as appropriate. (Reduce the task to a binary classification problem, drop any non-conforming records.) (5 pts.)\n",
        "\n",
        "2. Develop a classifier model with 128 densely-connected nodes (relu activation function) with a BERT-based embedding layer. Use 80% of data for model training. Assess model performance (Recall, Precision, Accuracy, ROC AUC, PR AUC). (10 pts.)\n",
        "\n",
        "3. Does the model have predictive value? Provide the rationale for your answer.(5 pts.)\n",
        "\n",
        "Submit LastnameFirstname-A6.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6PL_x-YOzRz"
      },
      "source": [
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L08OmhH-uhHw"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyC_wtxDu8KT"
      },
      "source": [
        "1. Import and pre-process the dataset as appropriate. (Reduce the task to a binary classification problem, drop any non-conforming records.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4QAHMdqBu_fL",
        "outputId": "df905a0b-4876-44f7-bc9b-5546760e02e6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pfactst = pd.read_csv('politifact-trump.csv')\n",
        "\n",
        "pfactst.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Date</th>\n",
              "      <th>Quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>July 22, 2021</td>\n",
              "      <td>\"The cost of an automobile, it's kind of back ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>June 23, 2021</td>\n",
              "      <td>\"The Second Amendment, from the day it was pas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>May 3, 2021</td>\n",
              "      <td>For vaccine rates among Americans 65 and older...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>March 25, 2021</td>\n",
              "      <td>“We’re sending back the vast majority of the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>February 16, 2021</td>\n",
              "      <td>\"If we kept (the minimum wage) indexed to infl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Score               Date                                              Quote\n",
              "0  False      July 22, 2021  \"The cost of an automobile, it's kind of back ...\n",
              "1  False      June 23, 2021  \"The Second Amendment, from the day it was pas...\n",
              "2  False        May 3, 2021  For vaccine rates among Americans 65 and older...\n",
              "3  False     March 25, 2021  “We’re sending back the vast majority of the f...\n",
              "4  False  February 16, 2021  \"If we kept (the minimum wage) indexed to infl..."
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI-BOVw_vpqA",
        "outputId": "b3c513dc-80ef-4480-8434-32f8d9bed5b0"
      },
      "source": [
        "pfactst.Score.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False            454\n",
              "Half True        331\n",
              "Mostly True      295\n",
              "Mostly False     290\n",
              "True             183\n",
              "Pants on Fire    180\n",
              "Score              2\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8yRkPy8vve9",
        "outputId": "629b3204-535c-4822-db19-9ac01a5be082"
      },
      "source": [
        "pfactst.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1735, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WfcoEsnPvyh0",
        "outputId": "46439793-f28b-4439-afe6-66b618bebf8a"
      },
      "source": [
        "pfactst = pfactst.loc[pfactst['Score'] != 'Score']\n",
        "pfactst['score'] = pfactst['Score'].replace({'Pants on Fire':1, 'Mostly False':1, 'False':1,\n",
        "                                               'True':0, 'Mostly True':0, 'Half True':1})\n",
        "pfactst.drop(['Date', 'Score'], axis=1, inplace=True)\n",
        "\n",
        "pfactst.score.hist()\n",
        "\n",
        "print('False score proportion: ', pfactst.score.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False score proportion:  0.7241777264858626\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pfactst.head()"
      ],
      "metadata": {
        "id": "G1Oj3eV2xppj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0191870d-b587-4799-b3cf-08098e0891d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"The cost of an automobile, it's kind of back ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"The Second Amendment, from the day it was pas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For vaccine rates among Americans 65 and older...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“We’re sending back the vast majority of the f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"If we kept (the minimum wage) indexed to infl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  score\n",
              "0  \"The cost of an automobile, it's kind of back ...      1\n",
              "1  \"The Second Amendment, from the day it was pas...      1\n",
              "2  For vaccine rates among Americans 65 and older...      1\n",
              "3  “We’re sending back the vast majority of the f...      1\n",
              "4  \"If we kept (the minimum wage) indexed to infl...      1"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAyxf1_HwNgX",
        "outputId": "cda26210-3447-422d-83da-9b29ad272007"
      },
      "source": [
        "pfactst.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1733, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLT9GvAUwXlT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = pfactst['Quote']\n",
        "y = pfactst['score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcZ2ewMRwqhE"
      },
      "source": [
        "2. Develop a classifier model with 128 densely-connected nodes (relu activation function) with a BERT-based embedding layer. Use 80% of data for model training. Assess model performance (Recall, Precision, Accuracy, ROC AUC, PR AUC)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "jDlckk-Hwu3f",
        "outputId": "3937e382-14bf-4bf5-c7a8-d1a79f4cf5b9"
      },
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLrQOBH1oE-"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qmKjwMB6edj"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QELasDT96j6K"
      },
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dense(128,activation='relu')(net)\n",
        "  net = tf.keras.layers.Dropout(0.2)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rMHRcZy6s3p"
      },
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LRjb34k6vny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8446c67c-e7f9-460a-d717-55ae7c697696"
      },
      "source": [
        "classifier_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  28763649    ['preprocessing[0][0]',          \n",
            "                                 (None, 128, 512),                'preprocessing[0][1]',          \n",
            "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
            "                                 [(None, 128, 512),                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                512)}                                                             \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          65664       ['BERT_encoder[0][5]']           \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 1)            129         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,829,442\n",
            "Trainable params: 28,829,441\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxNGp__W63lG"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0mZFg6B64cM"
      },
      "source": [
        "from keras.metrics import *\n",
        "\n",
        "METRICS = [\n",
        "      BinaryAccuracy(name='accuracy'),\n",
        "      Precision(name='precision'),\n",
        "      Recall(name='recall'),\n",
        "      AUC(name='auc'),\n",
        "      AUC(name='prc', curve='PR'), \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a2kQh8C7BSA"
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = 100\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oECJUyRW7EmF"
      },
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=METRICS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GZ4Z6BG7Hah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b095fc9-6638-406f-ed02-8fc5759539c0"
      },
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=X_train.values,y=y_train,\n",
        "                               validation_data=(X_test.values,y_test),\n",
        "                               epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/10\n",
            "44/44 [==============================] - 348s 8s/step - loss: 0.5999 - accuracy: 0.6977 - precision: 0.7266 - recall: 0.9321 - auc: 0.5678 - prc: 0.7752 - val_loss: 0.5502 - val_accuracy: 0.7320 - val_precision: 0.7320 - val_recall: 1.0000 - val_auc: 0.6680 - val_prc: 0.8351\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 338s 8s/step - loss: 0.5703 - accuracy: 0.7136 - precision: 0.7305 - recall: 0.9560 - auc: 0.6386 - prc: 0.8126 - val_loss: 0.5307 - val_accuracy: 0.7378 - val_precision: 0.7539 - val_recall: 0.9528 - val_auc: 0.7093 - val_prc: 0.8655\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 339s 8s/step - loss: 0.5391 - accuracy: 0.7323 - precision: 0.7528 - recall: 0.9371 - auc: 0.7014 - prc: 0.8517 - val_loss: 0.5247 - val_accuracy: 0.7262 - val_precision: 0.7556 - val_recall: 0.9252 - val_auc: 0.7166 - val_prc: 0.8722\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 339s 8s/step - loss: 0.4892 - accuracy: 0.7605 - precision: 0.7871 - recall: 0.9161 - auc: 0.7797 - prc: 0.8955 - val_loss: 0.5154 - val_accuracy: 0.7349 - val_precision: 0.7700 - val_recall: 0.9094 - val_auc: 0.7317 - val_prc: 0.8742\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 338s 8s/step - loss: 0.4193 - accuracy: 0.8110 - precision: 0.8273 - recall: 0.9331 - auc: 0.8571 - prc: 0.9352 - val_loss: 0.5731 - val_accuracy: 0.6945 - val_precision: 0.8109 - val_recall: 0.7598 - val_auc: 0.7271 - val_prc: 0.8767\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 337s 8s/step - loss: 0.3658 - accuracy: 0.8391 - precision: 0.8642 - recall: 0.9221 - auc: 0.8937 - prc: 0.9536 - val_loss: 0.6193 - val_accuracy: 0.6916 - val_precision: 0.8387 - val_recall: 0.7165 - val_auc: 0.7292 - val_prc: 0.8781\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 336s 8s/step - loss: 0.2991 - accuracy: 0.8745 - precision: 0.8972 - recall: 0.9331 - auc: 0.9339 - prc: 0.9715 - val_loss: 0.5880 - val_accuracy: 0.7291 - val_precision: 0.7878 - val_recall: 0.8622 - val_auc: 0.7286 - val_prc: 0.8733\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 337s 8s/step - loss: 0.2140 - accuracy: 0.9206 - precision: 0.9329 - recall: 0.9590 - auc: 0.9688 - prc: 0.9850 - val_loss: 0.6584 - val_accuracy: 0.7032 - val_precision: 0.8107 - val_recall: 0.7756 - val_auc: 0.7315 - val_prc: 0.8809\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 336s 8s/step - loss: 0.1643 - accuracy: 0.9430 - precision: 0.9484 - recall: 0.9740 - auc: 0.9805 - prc: 0.9895 - val_loss: 0.7359 - val_accuracy: 0.6888 - val_precision: 0.8093 - val_recall: 0.7520 - val_auc: 0.7191 - val_prc: 0.8737\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 336s 8s/step - loss: 0.1160 - accuracy: 0.9589 - precision: 0.9609 - recall: 0.9830 - auc: 0.9908 - prc: 0.9948 - val_loss: 0.8237 - val_accuracy: 0.6801 - val_precision: 0.7967 - val_recall: 0.7559 - val_auc: 0.7152 - val_prc: 0.8682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGlB8tSM7OpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6de3a5f-e58d-45fc-d144-afe1d8a20bff"
      },
      "source": [
        "model_results = classifier_model.evaluate(X_test.values, y_test, batch_size=128, verbose=0)\n",
        "\n",
        "for name, value in zip(classifier_model.metrics_names, model_results):\n",
        "  print(name, ': ', value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.8236870169639587\n",
            "accuracy :  0.680115282535553\n",
            "precision :  0.7966805100440979\n",
            "recall :  0.7559055089950562\n",
            "auc :  0.7152230739593506\n",
            "prc :  0.8681690096855164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overall, the model's results show good performance given the particular thresholds used.**\n",
        "\n",
        "**Accuracy at 0.68 means 68% of the time the model will predict either class accurately.**\n",
        "\n",
        "**Recall at 0.755 is quite encouraging. This means that 75.5% of the time this model predicts False statements, which is the class of interest.**\n",
        "\n",
        "**With Precision at almost 80%, out of those 75.5% False predictions, almost 80% of the time those predictions will be correct. These are reasonably good results given the thresholds used.**\n",
        "\n",
        "**The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a ROC AUC score of about 71.5%, the interpretation is that the model does have a level of predictive power.**\n",
        "\n",
        "**The ROC PRC also showed promising results at 0.868.**"
      ],
      "metadata": {
        "id": "k7Mbw7mmy7l8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZfXmXdy7QFu"
      },
      "source": [
        "3. Does the model have predictive value? Provide the rationale for your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Given the results for the given thresholds, this model does have predictive value. Being that the model's ROC AUC is above 0.5, this is the most accurate metric to assess model predictive power. However, if improving model performance even more is beneficial for the particular business case objective, altering threshold levels should be considered.**"
      ],
      "metadata": {
        "id": "cL0nTWT40z5m"
      }
    }
  ]
}