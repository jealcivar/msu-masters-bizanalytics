{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlcivarJoffre-A4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZHN309uVqfY"
      },
      "source": [
        "#Build Naive Bayes, SVM, Decision Tree, Boosted Tree, Random Forest, and ANN classifiers to predict positive/negative sentiment for a coffee maker.\n",
        "\n",
        "1. Preprocess data. Create a label column based on the product ratings. Negative sentiment is the outcome of interest. Ratings 1-3 -> negative sentiment. Ratings 4-5 -> positive sentiment. Assess label class distribution. (2 pts.)\n",
        "\n",
        "2. Build feature representations of the reviews. Transform all words to lower case, exclude English stopwords, develop TFIDF transformed feature representation. (2 pts.)\n",
        "\n",
        "3. Develop the classifiers to predict review sentiment. Evaluate average precision, recall, F1, ROC AUC, and PR AUC. (12 pts.)\n",
        "\n",
        "4. Identify the best performing model. Explain your choice of metric. (4 pts.)\n",
        "\n",
        "<p>\n",
        "Submit LastnameFirstname-A4.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaCgXTq_hNrm"
      },
      "source": [
        "# 1. Preprocess data. Create a label column based on the product ratings. Negative sentiment is the outcome of interest. Ratings 1-3 -> negative sentiment. Ratings 4-5 -> positive sentiment. Assess label class distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8gjsaw0VeVe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('coffee_maker.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ORmX7kZGVzBJ",
        "outputId": "33be5cfa-4fd6-4da5-9698-622cf37c3b87"
      },
      "source": [
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_date</th>\n",
              "      <th>handle</th>\n",
              "      <th>rating</th>\n",
              "      <th>helpfulness_rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>April 14, 2018</td>\n",
              "      <td>The Dolphin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>513</td>\n",
              "      <td>Delightful coffee maker if you’re only looking...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>February 7, 2019</td>\n",
              "      <td>Karen Kaffenberger</td>\n",
              "      <td>1.0</td>\n",
              "      <td>122</td>\n",
              "      <td>UPDATE: Bought this 10-21-18 and I finally ret...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>December 23, 2017</td>\n",
              "      <td>C1C3C11</td>\n",
              "      <td>4.0</td>\n",
              "      <td>185</td>\n",
              "      <td>The big reason I ordered this was because I wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>November 26, 2016</td>\n",
              "      <td>Paul Roberts</td>\n",
              "      <td>5.0</td>\n",
              "      <td>224</td>\n",
              "      <td>I've owned several of their older brewstation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>November 28, 2017</td>\n",
              "      <td>JennyD</td>\n",
              "      <td>3.0</td>\n",
              "      <td>116</td>\n",
              "      <td>I agonized over which coffee maker to purchase...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         review_date  ...                                             review\n",
              "0     April 14, 2018  ...  Delightful coffee maker if you’re only looking...\n",
              "1   February 7, 2019  ...  UPDATE: Bought this 10-21-18 and I finally ret...\n",
              "2  December 23, 2017  ...  The big reason I ordered this was because I wa...\n",
              "3  November 26, 2016  ...  I've owned several of their older brewstation ...\n",
              "4  November 28, 2017  ...  I agonized over which coffee maker to purchase...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmlZVHZBV2uh"
      },
      "source": [
        "ratings.drop(['review_date', 'handle', 'helpfulness_rating'], axis=1, inplace=True)\n",
        "ratings['sentiment'] = ratings['rating'].replace({1:1, 2:1, 3:1, 4:0, 5:0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BWG7TEtxWf3c",
        "outputId": "5b71fd8c-e5d4-45fd-840b-36c7b92570c9"
      },
      "source": [
        "ratings.sentiment.hist()\n",
        "\n",
        "print('Negative sentiment proportion: ', ratings.sentiment.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative sentiment proportion:  0.4128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh5199I2yf9k"
      },
      "source": [
        "**Upon re-labeling and replacing sentiment scores of either 0 or 1, it was identified that 41.28% of the data reflected Negative rating scores. The Negative rating scores (or Class 1) is the outcome class of interest because the negative sentiments will reflect where the root of information regarding product improvement and development will come from.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itR4npeWhWmw"
      },
      "source": [
        "# 2. Build feature representations of the reviews. Transform all words to lower case, exclude English stopwords, develop TFIDF transformed feature representation.\n",
        "\n",
        "                   &   \n",
        "# 3. Develop the classifiers to predict review sentiment. Evaluate average precision, recall, F1, ROC AUC, and PR AUC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oUxceyqXTKg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = ratings['review'].values.astype(str)\n",
        "y = ratings['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-7UwiuQYh0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8a7b56-6eb7-40c0-8c43-407d59a5388b"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score, roc_curve, auc, precision_recall_curve\n",
        "\n",
        "\n",
        "names = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Decision Tree', \n",
        "         'Random Forest','Boosted Tree', 'Neural Network']\n",
        "\n",
        "classifiers = [LogisticRegression(),\n",
        "               MultinomialNB(),\n",
        "               SVC(probability=True),\n",
        "               DecisionTreeClassifier(max_depth=5),\n",
        "               RandomForestClassifier(max_depth=5, n_estimators=10),\n",
        "               AdaBoostClassifier(),\n",
        "               MLPClassifier(alpha=1, max_iter=1000)\n",
        "               ]\n",
        "\n",
        "for name, classifier in zip(names, classifiers):\n",
        "  classifier_pipe = Pipeline([\n",
        "                            ('tfidf', TfidfVectorizer(lowercase=True, stop_words={'english'})),\n",
        "                            (name, classifier),\n",
        "                            ])\n",
        "  \n",
        "  classifier_pipe.fit(X_train, y_train)\n",
        "  pred = classifier_pipe.predict(X_test)\n",
        "  pred_prob = classifier_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, pred_prob)\n",
        "  precision, recall, thresholds_pr = precision_recall_curve(y_test, pred)\n",
        "\n",
        "  print(name, '\\n')\n",
        "  print(classification_report(y_test, pred))\n",
        "  print('ROC AUC: ', auc(fpr, tpr))\n",
        "  print('Precision/Recall AUC: ', auc(precision, recall))\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.92      0.89       935\n",
            "         1.0       0.89      0.80      0.84       715\n",
            "\n",
            "    accuracy                           0.87      1650\n",
            "   macro avg       0.87      0.86      0.86      1650\n",
            "weighted avg       0.87      0.87      0.87      1650\n",
            "\n",
            "ROC AUC:  0.9403896638121236\n",
            "Precision/Recall AUC:  0.4532092533947248\n",
            "\n",
            "\n",
            "Naive Bayes \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.96      0.86       935\n",
            "         1.0       0.93      0.65      0.77       715\n",
            "\n",
            "    accuracy                           0.83      1650\n",
            "   macro avg       0.86      0.81      0.82      1650\n",
            "weighted avg       0.85      0.83      0.82      1650\n",
            "\n",
            "ROC AUC:  0.9312501402340976\n",
            "Precision/Recall AUC:  0.433995337995338\n",
            "\n",
            "\n",
            "SVM \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.92      0.89       935\n",
            "         1.0       0.89      0.82      0.85       715\n",
            "\n",
            "    accuracy                           0.88      1650\n",
            "   macro avg       0.88      0.87      0.87      1650\n",
            "weighted avg       0.88      0.88      0.88      1650\n",
            "\n",
            "ROC AUC:  0.9459810777457835\n",
            "Precision/Recall AUC:  0.45900583988596133\n",
            "\n",
            "\n",
            "Decision Tree \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.54      0.66       935\n",
            "         1.0       0.59      0.87      0.70       715\n",
            "\n",
            "    accuracy                           0.68      1650\n",
            "   macro avg       0.72      0.71      0.68      1650\n",
            "weighted avg       0.74      0.68      0.68      1650\n",
            "\n",
            "ROC AUC:  0.769525447814218\n",
            "Precision/Recall AUC:  0.3259788540017766\n",
            "\n",
            "\n",
            "Random Forest \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.97      0.76       935\n",
            "         1.0       0.86      0.26      0.40       715\n",
            "\n",
            "    accuracy                           0.66      1650\n",
            "   macro avg       0.75      0.61      0.58      1650\n",
            "weighted avg       0.73      0.66      0.61      1650\n",
            "\n",
            "ROC AUC:  0.789446916719644\n",
            "Precision/Recall AUC:  0.28687591478289154\n",
            "\n",
            "\n",
            "Boosted Tree \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.89      0.84       935\n",
            "         1.0       0.83      0.71      0.77       715\n",
            "\n",
            "    accuracy                           0.81      1650\n",
            "   macro avg       0.82      0.80      0.81      1650\n",
            "weighted avg       0.81      0.81      0.81      1650\n",
            "\n",
            "ROC AUC:  0.8894110167906958\n",
            "Precision/Recall AUC:  0.4008846382375794\n",
            "\n",
            "\n",
            "Neural Network \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.91      0.89       935\n",
            "         1.0       0.88      0.82      0.84       715\n",
            "\n",
            "    accuracy                           0.87      1650\n",
            "   macro avg       0.87      0.86      0.87      1650\n",
            "weighted avg       0.87      0.87      0.87      1650\n",
            "\n",
            "ROC AUC:  0.9435982199618562\n",
            "Precision/Recall AUC:  0.45270483902062847\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_wgOEeDfz84"
      },
      "source": [
        "**Based on the chosen thresholds, the Logistic Regression model's results are as follows:**\n",
        "\n",
        "This model is able to identify 80% of Negative ratings (recall of Class 1). Of those, 89% of them are actually Negative (precision of Class 1).\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 89% and 84%, respectively.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a high ROC AUC score of 94%, the interpretation is that the model performs very well at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 45%, this model does suggest to have predicted value, however, the default threshold should be addressed to attain an improved level of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNPmCQSQg67l"
      },
      "source": [
        "**Based on the chosen thresholds, the Naive Bayes model's results are as follows:**\n",
        "\n",
        "This model is able to identify 65% of Negative ratings (recall of Class 1). Of those, 93% of them are actually Negative (precision of Class 1).\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 86% and 77%, respectively.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a high ROC AUC score of 93%, the interpretation is that the model performs very well at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 43.3%, this model does suggest to have predicted value, however, the default threshold should be addressed to attain an improved level of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVy1I3shCqk"
      },
      "source": [
        "**Based on the chosen thresholds, the SVM model's results are as follows:**\n",
        "\n",
        "This model is able to identify 82% of Negative ratings (recall of Class 1). Of those, 89% of them are actually Negative (precision of Class 1).\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 89% and 85%, respectively.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a high ROC AUC score of 94.6%, the interpretation is that the model performs very well at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 45.9%, this model does suggest to have predicted value, however, the default threshold should be addressed to attain an improved level of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmRYDEUDhEDt"
      },
      "source": [
        "**Based on the chosen thresholds, the Decision Tree model's results are as follows:**\n",
        "\n",
        "This model is able to identify 87% of Negative ratings (recall of Class 1). Of those, 59% of them are actually Negative which is not very good (precision of Class 1).\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 66% and 70%, respectively.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a ROC AUC score of 76.9%, the interpretation is that the model is decent at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 32.5%, this model suggests to have low predicted value and the default threshold should be addressed to attain an improved level of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsVCybL-hFSO"
      },
      "source": [
        "**Based on the chosen thresholds, the Random Forest model's results are as follows**:\n",
        "\n",
        "This model is able to identify 26% of Negative ratings which is very poor (recall of Class 1). Of those, 86% of them are actually Negative (precision of Class 1). With results like these, it is implied that the Random Forest model will not turn out to be useful in this particular business case.\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 76% and 40%, respectively. This indicates the class of interest suffer significantly with model identification.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With ROC AUC score of 78.9%, the interpretation is that the model is decent at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 28.6, this model has the lowest predicted value among all models analyzed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "talyaGlEhGyQ"
      },
      "source": [
        "**Based on the chosen thresholds, the Boosted Tree model's results are as follows:**\n",
        "\n",
        "This model is able to identify 71% of Negative ratings (recall of Class 1). Of those, 83% of them are actually Negative (precision of Class 1).\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 84% and 77%, respectively.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a high ROC AUC score of 88.9%, the interpretation is that the model performs very well at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 40%, this model does suggest to have predicted value, however, the default threshold should be addressed to attain an improved level of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWhSSvw6hH-8"
      },
      "source": [
        "**Based on the chosen thresholds, the Neural Network model's results are as follows:**\n",
        "\n",
        "This model is able to identify 82% of Negative ratings (recall of Class 1). Of those, 88% of them are actually Negative (precision of Class 1).\n",
        "\n",
        "The F1 scores are the harmonic averages of Positive and Negative sentiments. Both produced verily high scores of 89% and 84%, respectively.\n",
        "\n",
        "The ROC AUC plots the distribution of True Positive cases vs. False Positive cases throughout different levels of thresholds. With a high ROC AUC score of 94%, the interpretation is that the model performs very well at distinguishing between positive and negative cases.\n",
        "\n",
        "With a precision/recall AUC of 45%, this model does suggest to have predicted value, however, the default threshold should be addressed to attain an improved level of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76uaFtSahplG"
      },
      "source": [
        "# 4. Identify the best performing model. Explain your choice of metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovSHTCZxza8L"
      },
      "source": [
        "**The best performing model was the SVM model which performed just slightly better than the Neural Network. While both model's had Recall scores of 82%, the SVM model's Precision score was slightly higher than the Neural Network's precision score 89% vs. 88%.**\n",
        "\n",
        "**With the same Recall score for both Positive and Negative sentiment cases, the distinguishing stat between these two models is in their Precision. As a result, the SVM holds the superior F1 scores of 89% for Positive sentiment cases and 85% for Negative sentiment cases.**\n",
        "\n",
        "**Being that this business cases relies on the Negative sentiment cases for feedback on product improvement and product development, high identification stats for class 1 in particular is the prevailing reason why the SVM model is best in this particular business problem.**"
      ]
    }
  ]
}